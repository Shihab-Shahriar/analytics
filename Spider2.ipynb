{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from time import perf_counter\n",
    "import numpy as np,os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, StratifiedKFold\n",
    "from imblearn.under_sampling import InstanceHardnessThreshold, RandomUnderSampler, EditedNearestNeighbours\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef, precision_recall_curve, auc, accuracy_score, precision_score, recall_score\n",
    "import seaborn as sns,matplotlib.pyplot as plt\n",
    "\n",
    "from library.configs import CLFS, CV, SCORERS\n",
    "from library.utils import evaluate, read_data\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASETS = ['groovy-1_5_7.csv','jruby-1.4.0.csv','lucene-2.9.0.csv','jruby-1.7.0.preview1.csv','groovy-1_6_BETA_1.csv',\n",
    "        'derby-10.2.1.6.csv','wicket-1.5.3.csv','camel-2.9.0.csv','camel-1.4.0.csv','activemq-5.8.0.csv']\n",
    "DATASETS = [f for f in os.listdir(\"JIRA/\") if 'csv' in f]\n",
    "len(DATASETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin, clone\n",
    "class Spyder(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self,estimator,K=5):\n",
    "        self.estimator = estimator\n",
    "        self.K = K\n",
    "        \n",
    "    def sample(self,X,Y,sample_weight):    # SPIDER2, relabel=False and ampl=weak by default\n",
    "        if sample_weight is None:\n",
    "            sample_weight = np.ones_like(Y)\n",
    "\n",
    "        # First step, Remove unsafe samples from majority, \n",
    "        enn = EditedNearestNeighbours(sampling_strategy='majority',n_neighbors=5,kind_sel='mode')\n",
    "        Xs,Ys = enn.fit_resample(X,Y)\n",
    "        sample_weight = sample_weight[enn.sample_indices_]\n",
    "            \n",
    "        #Second, upsample unsafe minority samples\n",
    "        disagreement = (kDN(Xs,Ys,K=5,weight='uniform') * 5).astype('int')\n",
    "        agreement = 5 - disagreement\n",
    "\n",
    "        n = disagreement - agreement  #Number of times to upsample\n",
    "        n[Ys==0] = 0  #Don't upsample majority-class samples\n",
    "        n[n<0] = 0\n",
    "\n",
    "        Xt,Yt,SWt = Xs.copy(),Ys.copy(),sample_weight.copy()\n",
    "        while n.sum()>0:\n",
    "            Xtmp, Ytmp, SWtmp = Xs[n>0].copy(),Ys[n>0].copy(),sample_weight[n>0].copy()\n",
    "            Xt,Yt,SWt = np.concatenate((Xt,Xtmp)),np.concatenate((Yt,Ytmp)),np.concatenate((SWt,SWtmp))\n",
    "            \n",
    "            n -= 1\n",
    "            n[n==-1] = 0\n",
    "            \n",
    "        return Xt,Yt,SWt\n",
    "    \n",
    "    def fit(self, X, Y,sample_weight=None):\n",
    "        Xf,Yf,sample_weight = self.sample(X, Y, sample_weight)\n",
    "#         a,b = np.unique(Y,return_counts=True)[1],np.unique(Yf,return_counts=True)[1]\n",
    "#         print(a.max()/a.min(),b.max()/b.min(),a,b,Xf.shape,len(Xf)/len(X))\n",
    "        assert len(np.unique(Yf))==2,\"Pos class completely filtered out\"\n",
    "        try:\n",
    "            self.estimator = self.estimator.fit(Xf, Yf,sample_weight=sample_weight)\n",
    "        except TypeError as e:\n",
    "            self.estimator = self.estimator.fit(Xf, Yf)\n",
    "        return self\n",
    "\n",
    "    @property\n",
    "    def classes_(self):\n",
    "        return self.estimator.classes_\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.estimator.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.estimator.predict_proba(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys([('Spyder', 'dt'), ('Spyder', 'lr'), ('Spyder', 'nb'), ('Spyder', 'svm'), ('Spyder', 'knn'), ('Spyder', 'rf')]),\n",
       " 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {}\n",
    "for c,clf in CLFS.items():\n",
    "    models[('Spyder',c)] = Spyder(clf)    \n",
    "    \n",
    "models.keys(),len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Spyder.csv\"\n",
    "cols = pd.MultiIndex.from_product([['Spyder'],CLFS.keys(),[f.__name__ for f in SCORERS]],names=['imb','clf','metric'])\n",
    "df = pd.DataFrame(index=DATASETS,columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for it,d in enumerate(DATASETS):\n",
    "    print(it)\n",
    "    X,y_noisy,y_real = read_data(d,stats=True)\n",
    "    for k in models:\n",
    "        print(k)\n",
    "        sd = perf_counter()\n",
    "        r = evaluate(models[k],X,y_noisy,y_real,CV,SCORERS)\n",
    "        for f in r:\n",
    "            df.loc[d,(k[0],k[1],f)] = r[f].mean()\n",
    "        print(round(perf_counter()-sd,2),[round(r[f].mean(),3) for f in r])\n",
    "    print()\n",
    "    df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
