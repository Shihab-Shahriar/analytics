{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np,os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from imblearn.ensemble import BalancedBaggingClassifier, RUSBoostClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, EditedNearestNeighbours, TomekLinks\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef, precision_recall_curve, auc, accuracy_score, precision_score, recall_score\n",
    "import seaborn as sns,matplotlib.pyplot as plt\n",
    "\n",
    "from library.utils import evaluate, read_data\n",
    "from library.cleaners import kDN, ih_prob,FilteringEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise removal using Filtering\n",
    "By setting 3 thresholds on noise probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin, clone\n",
    "class CleaningEstimator(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, estimator, detector, K, threshold, random_state=None):\n",
    "        self.estimator = estimator\n",
    "        self.detector = detector\n",
    "        self.threshold = threshold\n",
    "        self.K = K\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, Y,sample_weight=None):\n",
    "        noise_prob = self.detector(X, Y, K=self.K)\n",
    "        to_keep = noise_prob<self.threshold\n",
    "        Xf, Yf = X[to_keep],Y[to_keep]\n",
    "        a,b = np.unique(Y,return_counts=True)[1],np.unique(Yf,return_counts=True)[1]\n",
    "        #print(a.max()/a.min(),b.max()/b.min())\n",
    "        try:\n",
    "            self.estimator = self.estimator.fit(Xf, Yf,sample_weight=sample_weight[to_keep])\n",
    "        except TypeError as e:\n",
    "            self.estimator = self.estimator.fit(Xf, Yf)\n",
    "        return self\n",
    "\n",
    "    @property\n",
    "    def classes_(self):\n",
    "        return self.estimator.classes_\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.estimator.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.estimator.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASETS = ['groovy-1_5_7.csv','jruby-1.4.0.csv','lucene-2.9.0.csv','jruby-1.7.0.preview1.csv','groovy-1_6_BETA_1.csv',\n",
    "        'derby-10.2.1.6.csv','wicket-1.5.3.csv','camel-2.9.0.csv','camel-1.4.0.csv','activemq-5.8.0.csv']\n",
    "DATASETS = [f for f in os.listdir(\"JIRA/\") if 'csv' in f]\n",
    "len(DATASETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbs = {\n",
    "    'smote': SMOTE(k_neighbors=5),\n",
    "    'rus': RandomUnderSampler('not minority'),\n",
    "    'wilson':EditedNearestNeighbours(n_neighbors=5),  #Default was 3\n",
    "    'tomek': TomekLinks(),\n",
    "}\n",
    "clfs = {\n",
    "    'dt': DecisionTreeClassifier(max_depth=20),\n",
    "    'lr': LogisticRegression(solver='lbfgs',max_iter=1000),\n",
    "    'nb': GaussianNB(),\n",
    "    'knn': KNeighborsClassifier(n_neighbors=5),\n",
    "    'rf': RandomForestClassifier(n_estimators=50),\n",
    "}\n",
    "bal_nb = CleaningEstimator(GaussianNB(),kDN,K=5,threshold=.999)\n",
    "bal_dt_20 = CleaningEstimator(DecisionTreeClassifier(max_depth=20,max_features='sqrt'),kDN,K=5,threshold=.999)\n",
    "bal_dt_boost = CleaningEstimator(DecisionTreeClassifier(max_depth=10),kDN,K=5,threshold=.999)\n",
    "ensembles = {\n",
    "    'rboost_DT': RUSBoostClassifier(base_estimator=clone(bal_dt_boost),algorithm='SAMME',n_estimators=10),\n",
    "    'rboost_NB': RUSBoostClassifier(base_estimator=clone(bal_nb),algorithm='SAMME',n_estimators=10),\n",
    "    'bbag_DT': BalancedBaggingClassifier(base_estimator=clone(bal_dt_20),n_estimators=50),\n",
    "    'bbag_NB': BalancedBaggingClassifier(base_estimator=clone(bal_nb),n_estimators=50),\n",
    "}\n",
    "simples = {\n",
    "    'LR': LogisticRegression(solver='lbfgs',max_iter=1000),\n",
    "    'RF': RandomForestClassifier(n_estimators=50)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys([('smote', 'dt'), ('smote', 'lr'), ('smote', 'nb'), ('smote', 'knn'), ('smote', 'rf'), ('rus', 'dt'), ('rus', 'lr'), ('rus', 'nb'), ('rus', 'knn'), ('rus', 'rf'), ('wilson', 'dt'), ('wilson', 'lr'), ('wilson', 'nb'), ('wilson', 'knn'), ('wilson', 'rf'), ('tomek', 'dt'), ('tomek', 'lr'), ('tomek', 'nb'), ('tomek', 'knn'), ('tomek', 'rf'), ('ens', 'rboost_DT'), ('ens', 'rboost_NB'), ('ens', 'bbag_DT'), ('ens', 'bbag_NB'), ('sim', 'LR'), ('sim', 'RF')]),\n",
       " 26)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {}\n",
    "for im,samp in imbs.items():\n",
    "    for c,clf in clfs.items():\n",
    "        models[(im,c)] = Pipeline([('samp',samp),('clf',CleaningEstimator(clf,kDN,K=5,threshold=.999))])\n",
    "\n",
    "for m,ens in ensembles.items():\n",
    "    models[('ens',m)] = ens\n",
    "    \n",
    "for m,clf in simples.items():\n",
    "    models[('sim',m)] = CleaningEstimator(clf,kDN,K=5,threshold=.999)    \n",
    "    \n",
    "models.keys(),len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10,n_repeats=3,random_state=None)\n",
    "def pr_rec_score(y,yp):\n",
    "    prec, rec, _ = precision_recall_curve(y,yp)\n",
    "    return auc(rec,prec)\n",
    "scorers = [matthews_corrcoef,pr_rec_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = pd.MultiIndex.from_product([imbs.keys(),clfs.keys(),[f.__name__ for f in scorers]],names=['imb','clf','metric'])\n",
    "df = pd.DataFrame(index=DATASETS,columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activemq-5.8.0.csv noise:0.058, imb:15.847,203,3217, Shape:(3420, 65)\n",
      "('smote', 'dt')\n",
      "('smote', 'lr')\n",
      "('smote', 'nb')\n",
      "('smote', 'knn')\n",
      "('smote', 'rf')\n",
      "('rus', 'dt')\n",
      "('rus', 'lr')\n",
      "('rus', 'nb')\n",
      "('rus', 'knn')\n",
      "('rus', 'rf')\n",
      "('wilson', 'dt')\n",
      "('wilson', 'lr')\n",
      "('wilson', 'nb')\n",
      "('wilson', 'knn')\n",
      "('wilson', 'rf')\n",
      "('tomek', 'dt')\n",
      "('tomek', 'lr')\n",
      "('tomek', 'nb')\n",
      "('tomek', 'knn')\n",
      "('tomek', 'rf')\n",
      "('ens', 'rboost_DT')\n",
      "('ens', 'rboost_NB')\n",
      "('ens', 'bbag_DT')\n",
      "('ens', 'bbag_NB')\n",
      "('sim', 'LR')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shihab/anaconda3/envs/ana/lib/python3.7/site-packages/sklearn/metrics/_classification.py:896: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/home/shihab/anaconda3/envs/ana/lib/python3.7/site-packages/sklearn/metrics/_classification.py:896: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/home/shihab/anaconda3/envs/ana/lib/python3.7/site-packages/sklearn/metrics/_classification.py:896: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sim', 'RF')\n",
      "groovy-1_6_BETA_1.csv noise:0.128, imb:6.017,117,704, Shape:(821, 65)\n",
      "('smote', 'dt')\n",
      "('smote', 'lr')\n",
      "('smote', 'nb')\n",
      "('smote', 'knn')\n",
      "('smote', 'rf')\n",
      "('rus', 'dt')\n",
      "('rus', 'lr')\n",
      "('rus', 'nb')\n",
      "('rus', 'knn')\n",
      "('rus', 'rf')\n",
      "('wilson', 'dt')\n",
      "('wilson', 'lr')\n",
      "('wilson', 'nb')\n",
      "('wilson', 'knn')\n",
      "('wilson', 'rf')\n",
      "('tomek', 'dt')\n",
      "('tomek', 'lr')\n",
      "('tomek', 'nb')\n",
      "('tomek', 'knn')\n",
      "('tomek', 'rf')\n",
      "('ens', 'rboost_DT')\n",
      "('ens', 'rboost_NB')\n",
      "('ens', 'bbag_DT')\n",
      "('ens', 'bbag_NB')\n",
      "('sim', 'LR')\n",
      "('sim', 'RF')\n",
      "activemq-5.3.0.csv noise:0.094, imb:15.669,142,2225, Shape:(2367, 65)\n",
      "('smote', 'dt')\n",
      "('smote', 'lr')\n",
      "('smote', 'nb')\n",
      "('smote', 'knn')\n",
      "('smote', 'rf')\n",
      "('rus', 'dt')\n",
      "('rus', 'lr')\n",
      "('rus', 'nb')\n",
      "('rus', 'knn')\n",
      "('rus', 'rf')\n",
      "('wilson', 'dt')\n",
      "('wilson', 'lr')\n",
      "('wilson', 'nb')\n",
      "('wilson', 'knn')\n",
      "('wilson', 'rf')\n",
      "('tomek', 'dt')\n",
      "('tomek', 'lr')\n",
      "('tomek', 'nb')\n",
      "('tomek', 'knn')\n",
      "('tomek', 'rf')\n",
      "('ens', 'rboost_DT')\n",
      "('ens', 'rboost_NB')\n",
      "('ens', 'bbag_DT')\n",
      "('ens', 'bbag_NB')\n"
     ]
    }
   ],
   "source": [
    "for d in DATASETS:\n",
    "    X,y_noisy,y_real = read_data(d,stats=True)\n",
    "    for k in models:\n",
    "        print(k)\n",
    "        r = evaluate(models[k],X,y_noisy,y_real,cv,scorers)\n",
    "        for f in r:\n",
    "            df.loc[d,(k[0],k[1],f)] = r[f].mean()\n",
    "    df.to_csv(\"Balancing->Filtering.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bal_dt_boost.estimator.fit(X,y_noisy)\n",
    "hasattr(bal_dt_boost.estimator,'classes_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
