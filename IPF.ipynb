{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from time import perf_counter\n",
    "import numpy as np,os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from imblearn.ensemble import BalancedBaggingClassifier, RUSBoostClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, EditedNearestNeighbours, TomekLinks, RepeatedEditedNearestNeighbours\n",
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef, precision_recall_curve, auc, accuracy_score, precision_score, recall_score\n",
    "import seaborn as sns,matplotlib.pyplot as plt\n",
    "\n",
    "from library.utils import evaluate, read_data\n",
    "from library.cleaners import kDN, ih_prob,FilteringEstimator\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "+ Need to take best value among samplers, since some don't completely balance, and IPF sucks there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASETS = ['groovy-1_5_7.csv','jruby-1.4.0.csv','lucene-2.9.0.csv','jruby-1.7.0.preview1.csv','groovy-1_6_BETA_1.csv',\n",
    "        'derby-10.2.1.6.csv','wicket-1.5.3.csv','camel-2.9.0.csv','camel-1.4.0.csv','activemq-5.8.0.csv']\n",
    "DATASETS = [f for f in os.listdir(\"JIRA/\") if 'csv' in f]\n",
    "len(DATASETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin, clone\n",
    "class IPF(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, estimator, n=5, max_iter = 3,random_state=None):\n",
    "        self.estimator = estimator\n",
    "        self.n = n\n",
    "        self.max_iter = max_iter\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def clean(self,X,Y, sample_weight):\n",
    "        Xt,Yt = shuffle(X,Y)\n",
    "        orig_size = len(X)\n",
    "        n_iters_with_small_change = 0\n",
    "        tmp = 0\n",
    "        while n_iters_with_small_change<self.max_iter:\n",
    "            tmp += 1\n",
    "            cur_size = len(Xt)\n",
    "            breaks = [(len(Xt)//self.n)*i for i in range(1,self.n)]\n",
    "            Xs,Ys = np.split(Xt,breaks),np.split(Yt,breaks)\n",
    "            \n",
    "            clfs = []\n",
    "            for i in range(self.n):\n",
    "                c = DecisionTreeClassifier(max_depth=2).fit(Xs[i],Ys[i])\n",
    "                clfs.append(c)\n",
    "\n",
    "            preds = np.zeros((len(Xt),self.n))\n",
    "            for i in range(self.n):\n",
    "                preds[:,i] = clfs[i].predict(Xt)\n",
    "            eqs = preds==Yt.reshape(-1,1)  # Shape: (len(Xt),self.n)\n",
    "            clean_idx = eqs.sum(axis=1)>=(self.n/2)  # Idx of clean samples\n",
    "            \n",
    "            try:\n",
    "                sample_weight = sample_weight[clean_idx]\n",
    "            except:\n",
    "                pass\n",
    "            Xt,Yt = Xt[clean_idx],Yt[clean_idx]\n",
    "            \n",
    "            cur_change = cur_size - len(Xt)\n",
    "            if cur_change<=.01*orig_size:\n",
    "                n_iters_with_small_change += 1\n",
    "            else:\n",
    "                n_iters_with_small_change = 0  #Because these small change has to be consecutively 3 times\n",
    "            #print(tmp,cur_change,orig_size,cur_change/orig_size)  \n",
    "        return Xt,Yt,sample_weight\n",
    "\n",
    "\n",
    "    def fit(self, X, Y,sample_weight=None):\n",
    "        Xf,Yf,sample_weight = self.clean(X, Y, sample_weight)\n",
    "        a,b = np.unique(Y,return_counts=True)[1],np.unique(Yf,return_counts=True)[1]\n",
    "        #print(a.max()/a.min(),b.max()/b.min(),a,b,Xf.shape,len(Xf)/len(X))\n",
    "        assert len(np.unique(Yf))==2,\"Pos class completely filtered out\"\n",
    "        try:\n",
    "            self.estimator = self.estimator.fit(Xf, Yf,sample_weight=sample_weight)\n",
    "        except TypeError as e:\n",
    "            self.estimator = self.estimator.fit(Xf, Yf)\n",
    "        return self\n",
    "\n",
    "    @property\n",
    "    def classes_(self):\n",
    "        return self.estimator.classes_\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.estimator.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.estimator.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbs = {\n",
    "    'smote': SMOTE(k_neighbors=5),\n",
    "    'rus': RandomUnderSampler('not minority'),\n",
    "    'wilson':EditedNearestNeighbours(n_neighbors=5,kind_sel='all'),  #Default was 3\n",
    "    'tomek': TomekLinks(),\n",
    "    'None': 'passthrough',\n",
    "}\n",
    "clfs = {\n",
    "    'dt': DecisionTreeClassifier(max_depth=20),\n",
    "    'lr': LogisticRegression(solver='lbfgs',max_iter=1000),\n",
    "    'nb': GaussianNB(),\n",
    "    'svm': SVC(probability=True),\n",
    "    'knn': KNeighborsClassifier(n_neighbors=5),\n",
    "    'rf': RandomForestClassifier(n_estimators=50),\n",
    "}\n",
    "bal_nb = IPF(GaussianNB())\n",
    "bal_dt_bag = IPF(DecisionTreeClassifier(max_depth=20,max_features='sqrt'))\n",
    "bal_dt_boost = IPF(DecisionTreeClassifier(max_depth=10))\n",
    "ensembles = {\n",
    "    'rboost_DT': RUSBoostClassifier(base_estimator=clone(bal_dt_boost),algorithm='SAMME',n_estimators=50),\n",
    "    'rboost_NB': RUSBoostClassifier(base_estimator=clone(bal_nb),algorithm='SAMME',n_estimators=50),\n",
    "    'bbag_DT': BalancedBaggingClassifier(base_estimator=clone(bal_dt_bag),n_estimators=50),\n",
    "    'bbag_NB': BalancedBaggingClassifier(base_estimator=clone(bal_nb),n_estimators=50),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys([('Spyder', 'BagNB'), ('Spyder', 'BagDT')]), 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {}\n",
    "# for im,samp in imbs.items():\n",
    "#     for c,clf in clfs.items():\n",
    "#         models[(im,c)] = Pipeline([('samp',samp),('clf',IPF(clf))])\n",
    "\n",
    "# for m,ens in ensembles.items():\n",
    "#     models[('ens',m)] = ens\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "nb = GaussianNB()\n",
    "dt = DecisionTreeClassifier(max_depth=20,max_features='sqrt')\n",
    "models[('Spyder',\"BagNB\")] = make_pipeline(SMOTE(),IPF(BaggingClassifier(base_estimator=nb,n_estimators=20)))\n",
    "models[('Spyder',\"BagDT\")] = make_pipeline(SMOTE(),IPF(BaggingClassifier(base_estimator=dt,n_estimators=20)))\n",
    "    \n",
    "    \n",
    "    \n",
    "models.keys(),len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=5,n_repeats=2,random_state=99)\n",
    "def pr_rec_score(y,yp):\n",
    "    prec, rec, _ = precision_recall_curve(y,yp)\n",
    "    return auc(rec,prec)\n",
    "scorers = [matthews_corrcoef,pr_rec_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = pd.MultiIndex.from_product([['Spyder'],[\"BagNB\",\"BagDT\"],[f.__name__ for f in scorers]],names=['imb','clf','metric'])\n",
    "df = pd.DataFrame(index=DATASETS,columns=cols)\n",
    "#df = pd.read_csv(\"IPF.csv\",header=[0,1,2],index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activemq-5.8.0.csv noise:0.058, imb:15.847,203,3217, Shape:(3420, 65)\n",
      "('Spyder', 'BagNB')\n",
      "1.79 [0.262, 0.421]\n",
      "('Spyder', 'BagDT')\n",
      "2.06 [0.246, 0.278]\n",
      "\n",
      "groovy-1_6_BETA_1.csv noise:0.128, imb:6.017,117,704, Shape:(821, 65)\n",
      "('Spyder', 'BagNB')\n",
      "0.6 [0.302, 0.433]\n",
      "('Spyder', 'BagDT')\n",
      "0.62 [0.386, 0.515]\n",
      "\n",
      "activemq-5.3.0.csv noise:0.094, imb:15.669,142,2225, Shape:(2367, 65)\n",
      "('Spyder', 'BagNB')\n",
      "1.44 [0.333, 0.464]\n",
      "('Spyder', 'BagDT')\n",
      "1.8 [0.328, 0.405]\n",
      "\n",
      "wicket-1.3.0-incubating-beta-1.csv noise:0.164, imb:4.806,288,1384, Shape:(1672, 65)\n",
      "('Spyder', 'BagNB')\n",
      "0.89 [0.293, 0.442]\n",
      "('Spyder', 'BagDT')\n",
      "0.92 [0.283, 0.393]\n",
      "\n",
      "jruby-1.1.csv noise:0.175, imb:3.540,161,570, Shape:(731, 65)\n",
      "('Spyder', 'BagNB')\n",
      "0.55 [0.403, 0.611]\n",
      "('Spyder', 'BagDT')\n",
      "0.54 [0.438, 0.595]\n",
      "\n",
      "jruby-1.4.0.csv noise:0.190, imb:3.890,200,778, Shape:(978, 65)\n",
      "('Spyder', 'BagNB')\n",
      "0.72 [0.433, 0.609]\n",
      "('Spyder', 'BagDT')\n",
      "0.69 [0.381, 0.589]\n",
      "\n",
      "lucene-2.3.0.csv noise:0.204, imb:4.031,160,645, Shape:(805, 65)\n",
      "('Spyder', 'BagNB')\n",
      "0.57 [0.481, 0.642]\n",
      "('Spyder', 'BagDT')\n",
      "0.61 [0.46, 0.689]\n",
      "\n",
      "hbase-0.95.2.csv noise:0.260, imb:15.088,114,1720, Shape:(1834, 65)\n",
      "('Spyder', 'BagNB')\n",
      "1.16 [0.317, 0.53]\n",
      "('Spyder', 'BagDT')\n",
      "1.49 [0.257, 0.484]\n",
      "\n",
      "lucene-3.0.0.csv noise:0.185, imb:6.037,190,1147, Shape:(1337, 65)\n",
      "('Spyder', 'BagNB')\n",
      "0.88 [0.309, 0.332]\n",
      "('Spyder', 'BagDT')\n",
      "1.0 [0.295, 0.295]\n",
      "\n",
      "camel-2.9.0.csv noise:0.044, imb:34.600,200,6920, Shape:(7120, 65)\n",
      "('Spyder', 'BagNB')\n",
      "3.81 [0.242, 0.375]\n",
      "('Spyder', 'BagDT')\n",
      "4.3 [0.24, 0.277]\n",
      "\n",
      "wicket-1.5.3.csv noise:0.064, imb:26.720,93,2485, Shape:(2578, 65)\n",
      "('Spyder', 'BagNB')\n",
      "1.57 [0.218, 0.394]\n",
      "('Spyder', 'BagDT')\n",
      "1.7 [0.196, 0.219]\n",
      "\n",
      "lucene-3.1.csv noise:0.120, imb:7.477,331,2475, Shape:(2806, 65)\n",
      "('Spyder', 'BagNB')\n",
      "1.59 [0.195, 0.279]\n",
      "('Spyder', 'BagDT')\n",
      "1.8 [0.176, 0.228]\n",
      "\n",
      "groovy-1_6_BETA_2.csv noise:0.096, imb:7.583,103,781, Shape:(884, 65)\n",
      "('Spyder', 'BagNB')\n",
      "0.7 [0.287, 0.396]\n",
      "('Spyder', 'BagDT')\n",
      "0.72 [0.318, 0.427]\n",
      "\n",
      "activemq-5.2.0.csv noise:0.113, imb:12.247,154,1886, Shape:(2040, 65)\n",
      "('Spyder', 'BagNB')\n",
      "1.24 [0.364, 0.542]\n",
      "('Spyder', 'BagDT')\n",
      "1.34 [0.34, 0.432]\n",
      "\n",
      "groovy-1_5_7.csv noise:0.085, imb:8.463,80,677, Shape:(757, 65)\n",
      "('Spyder', 'BagNB')\n",
      "0.65 [0.239, 0.448]\n",
      "('Spyder', 'BagDT')\n",
      "0.69 [0.266, 0.446]\n",
      "\n",
      "hbase-0.95.0.csv noise:0.234, imb:17.341,91,1578, Shape:(1669, 65)\n",
      "('Spyder', 'BagNB')\n",
      "1.14 [0.278, 0.479]\n",
      "('Spyder', 'BagDT')\n",
      "1.38 [0.233, 0.441]\n",
      "\n",
      "camel-2.11.0.csv noise:0.024, imb:43.230,200,8646, Shape:(8846, 65)\n",
      "('Spyder', 'BagNB')\n",
      "4.56 [0.168, 0.31]\n",
      "('Spyder', 'BagDT')\n",
      "5.58 [0.252, 0.218]\n",
      "\n",
      "jruby-1.7.0.preview1.csv noise:0.099, imb:8.902,163,1451, Shape:(1614, 65)\n",
      "('Spyder', 'BagNB')\n",
      "1.04 [0.29, 0.438]\n",
      "('Spyder', 'BagDT')\n",
      "1.22 [0.284, 0.328]\n",
      "\n",
      "hive-0.10.0.csv noise:0.126, imb:29.000,52,1508, Shape:(1560, 65)\n",
      "('Spyder', 'BagNB')\n",
      "1.09 [0.411, 0.5]\n",
      "('Spyder', 'BagDT')\n",
      "1.3 [0.317, 0.371]\n",
      "\n",
      "camel-2.10.0.csv noise:0.053, imb:24.447,311,7603, Shape:(7914, 65)\n",
      "('Spyder', 'BagNB')\n",
      "3.79 [0.22, 0.415]\n",
      "('Spyder', 'BagDT')\n",
      "4.49 [0.169, 0.28]\n",
      "\n",
      "derby-10.2.1.6.csv noise:0.290, imb:9.906,180,1783, Shape:(1963, 65)\n",
      "('Spyder', 'BagNB')\n",
      "1.19 [0.453, 0.689]\n",
      "('Spyder', 'BagDT')\n",
      "1.5 [0.356, 0.65]\n",
      "\n",
      "jruby-1.5.0.csv noise:0.218, imb:3.098,276,855, Shape:(1131, 65)\n",
      "('Spyder', 'BagNB')\n",
      "0.77 [0.336, 0.53]\n",
      "('Spyder', 'BagDT')\n",
      "0.72 [0.364, 0.5]\n",
      "\n",
      "derby-10.3.1.4.csv noise:0.267, imb:13.051,157,2049, Shape:(2206, 65)\n",
      "('Spyder', 'BagNB')\n",
      "1.39 [0.409, 0.648]\n",
      "('Spyder', 'BagDT')\n",
      "1.59 [0.384, 0.631]\n",
      "\n",
      "lucene-2.9.0.csv noise:0.226, imb:3.921,278,1090, Shape:(1368, 65)\n",
      "('Spyder', 'BagNB')\n",
      "0.95 [0.33, 0.48]\n",
      "('Spyder', 'BagDT')\n",
      "1.0 [0.28, 0.424]\n",
      "\n",
      "hbase-0.94.0.csv noise:0.207, imb:14.348,69,990, Shape:(1059, 65)\n",
      "('Spyder', 'BagNB')\n",
      "0.79 [0.414, 0.563]\n",
      "('Spyder', 'BagDT')\n",
      "0.9 [0.414, 0.543]\n",
      "\n",
      "camel-1.4.0.csv noise:0.281, imb:3.174,363,1152, Shape:(1515, 65)\n",
      "('Spyder', 'BagNB')\n",
      "0.85 [0.301, 0.509]\n",
      "('Spyder', 'BagDT')\n",
      "0.88 [0.333, 0.488]\n",
      "\n",
      "activemq-5.1.0.csv noise:0.083, imb:13.173,139,1831, Shape:(1970, 65)\n",
      "('Spyder', 'BagNB')\n",
      "1.19 [0.308, 0.444]\n",
      "('Spyder', 'BagDT')\n",
      "1.45 [0.304, 0.362]\n",
      "\n",
      "activemq-5.0.0.csv noise:0.139, imb:21.976,82,1802, Shape:(1884, 65)\n",
      "('Spyder', 'BagNB')\n",
      "1.3 [0.436, 0.592]\n",
      "('Spyder', 'BagDT')\n",
      "1.39 [0.512, 0.603]\n",
      "\n",
      "derby-10.5.1.1.csv noise:0.126, imb:14.028,180,2525, Shape:(2705, 65)\n",
      "('Spyder', 'BagNB')\n",
      "1.61 [0.37, 0.523]\n",
      "('Spyder', 'BagDT')\n",
      "1.84 [0.339, 0.435]\n",
      "\n",
      "wicket-1.3.0-beta2.csv noise:0.184, imb:4.780,305,1458, Shape:(1763, 65)\n",
      "('Spyder', 'BagNB')\n",
      "0.92 [0.3, 0.444]\n",
      "('Spyder', 'BagDT')\n",
      "0.91 [0.267, 0.395]\n",
      "\n",
      "hive-0.12.0.csv noise:0.087, imb:56.870,46,2616, Shape:(2662, 65)\n",
      "('Spyder', 'BagNB')\n",
      "1.64 [0.176, 0.265]\n",
      "('Spyder', 'BagDT')\n",
      "2.1 [0.108, 0.147]\n",
      "\n",
      "hive-0.9.0.csv noise:0.179, imb:25.717,53,1363, Shape:(1416, 65)\n",
      "('Spyder', 'BagNB')\n",
      "1.07 [0.437, 0.596]\n",
      "('Spyder', 'BagDT')\n",
      "1.25 [0.385, 0.544]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for d in DATASETS:\n",
    "    X,y_noisy,y_real = read_data(d,stats=True)\n",
    "    if df.loc[d,:].isna().sum()==0:\n",
    "        print(f\"SKIPPING {d}\\n\")\n",
    "        continue\n",
    "    for k in models:\n",
    "        print(k)\n",
    "        sd = perf_counter()\n",
    "        r = evaluate(models[k],X,y_noisy,y_real,cv,scorers)\n",
    "        for f in r:\n",
    "            df.loc[d,(k[0],k[1],f)] = r[f].mean()\n",
    "        print(round(perf_counter()-sd,2),[round(r[f].mean(),3) for f in r])\n",
    "    print()\n",
    "    df.to_csv(\"Smote_IPF.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipf = pd.read_csv(\"IPF.csv\",header=[0,1,2],index_col=0)\n",
    "ipf = ipf.drop(columns=['rboost_DT','rboost_NB'],level=1)\n",
    "smote_ipf = ipf['smote']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = pd.read_csv(\"Smote_IPF.csv\",header=[0,1,2],index_col=0).droplevel(0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 12), (32, 4))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote_ipf.shape,bag.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(MultiIndex([( 'dt', 'matthews_corrcoef'),\n",
       "             ( 'dt',      'pr_rec_score'),\n",
       "             ( 'lr', 'matthews_corrcoef'),\n",
       "             ( 'lr',      'pr_rec_score'),\n",
       "             ( 'nb', 'matthews_corrcoef'),\n",
       "             ( 'nb',      'pr_rec_score'),\n",
       "             ('svm', 'matthews_corrcoef'),\n",
       "             ('svm',      'pr_rec_score'),\n",
       "             ('knn', 'matthews_corrcoef'),\n",
       "             ('knn',      'pr_rec_score'),\n",
       "             ( 'rf', 'matthews_corrcoef'),\n",
       "             ( 'rf',      'pr_rec_score')],\n",
       "            names=['clf', 'metric']),\n",
       " MultiIndex([('BagNB', 'matthews_corrcoef'),\n",
       "             ('BagNB',      'pr_rec_score'),\n",
       "             ('BagDT', 'matthews_corrcoef'),\n",
       "             ('BagDT',      'pr_rec_score')],\n",
       "            names=['clf', 'metric']))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote_ipf.columns,bag.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([smote_ipf,bag],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv(\"Smote-IPF.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
