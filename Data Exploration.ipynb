{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np,os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, PowerTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold, GridSearchCV, cross_val_predict\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.io import arff\n",
    "from scipy.stats import spearmanr, pearsonr, linregress\n",
    "\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D\n",
    "\n",
    "from library.utils import evaluate, read_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalance & Noise Ratio\n",
    "+ IR is very for some datasets. Mean, std:14.96,12.39. Top 3: 34,43,56\n",
    "+ For noise, Mean, std:15.00,7.28\n",
    "+ Correlation between these two is statistically significant (r = -.52). So when noise is severe, IR isn't, vice-versa. So we don't have to tackle severe version of both at the same time.  \n",
    "+ Correlation between IR and size is statistically significant (r = +.62). Again, good news. \n",
    "+ Very, very weird structure when datasets are plotted in 3d using PCA. No visible structure with tSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = [f for f in os.listdir(\"JIRA/\") if 'csv' in f]\n",
    "SHORT = ['groovy-1_5_7.csv','jruby-1.4.0.csv','lucene-2.9.0.csv','jruby-1.7.0.preview1.csv','groovy-1_6_BETA_1.csv',\n",
    "        'derby-10.2.1.6.csv','wicket-1.5.3.csv','camel-2.9.0.csv','camel-1.4.0.csv','activemq-5.8.0.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real:206, Heu:203, Actual % Bugs,Clean: 0.522,0.969\n",
      "Real:70, Heu:117, Actual % Bugs,Clean: 0.350,0.959\n",
      "Real:258, Heu:142, Actual % Bugs,Clean: 0.627,0.924\n",
      "activemq-5.3.0.csv 0.6267605633802817\n",
      "Real:101, Heu:288, Actual % Bugs,Clean: 0.198,0.968\n",
      "Real:87, Heu:161, Actual % Bugs,Clean: 0.373,0.953\n",
      "Real:180, Heu:200, Actual % Bugs,Clean: 0.485,0.893\n",
      "Real:196, Heu:160, Actual % Bugs,Clean: 0.600,0.845\n",
      "lucene-2.3.0.csv 0.6\n",
      "Real:483, Heu:114, Actual % Bugs,Clean: 0.526,0.754\n",
      "Real:155, Heu:190, Actual % Bugs,Clean: 0.258,0.908\n",
      "Real:199, Heu:200, Actual % Bugs,Clean: 0.215,0.977\n",
      "Real:105, Heu:93, Actual % Bugs,Clean: 0.172,0.964\n",
      "Real:107, Heu:331, Actual % Bugs,Clean: 0.154,0.977\n",
      "Real:76, Heu:103, Actual % Bugs,Clean: 0.456,0.963\n",
      "Real:219, Heu:154, Actual % Bugs,Clean: 0.461,0.922\n",
      "Real:26, Heu:80, Actual % Bugs,Clean: 0.263,0.993\n",
      "Real:383, Heu:91, Actual % Bugs,Clean: 0.462,0.784\n",
      "Real:192, Heu:200, Actual % Bugs,Clean: 0.460,0.988\n",
      "Real:87, Heu:163, Actual % Bugs,Clean: 0.276,0.971\n",
      "Real:176, Heu:52, Actual % Bugs,Clean: 0.308,0.894\n",
      "Real:230, Heu:311, Actual % Bugs,Clean: 0.196,0.978\n",
      "Real:661, Heu:180, Actual % Bugs,Clean: 0.756,0.706\n",
      "derby-10.2.1.6.csv 0.7555555555555555\n",
      "Real:82, Heu:276, Actual % Bugs,Clean: 0.203,0.970\n",
      "Real:669, Heu:157, Actual % Bugs,Clean: 0.758,0.732\n",
      "derby-10.3.1.4.csv 0.7579617834394905\n",
      "Real:273, Heu:278, Actual % Bugs,Clean: 0.435,0.861\n",
      "Real:218, Heu:69, Actual % Bugs,Clean: 0.493,0.814\n",
      "Real:285, Heu:363, Actual % Bugs,Clean: 0.306,0.849\n",
      "Real:154, Heu:139, Actual % Bugs,Clean: 0.468,0.951\n",
      "Real:293, Heu:82, Actual % Bugs,Clean: 0.695,0.869\n",
      "activemq-5.0.0.csv 0.6951219512195121\n",
      "Real:383, Heu:180, Actual % Bugs,Clean: 0.617,0.892\n",
      "derby-10.5.1.1.csv 0.6166666666666667\n",
      "Real:130, Heu:305, Actual % Bugs,Clean: 0.180,0.949\n",
      "Real:213, Heu:46, Actual % Bugs,Clean: 0.304,0.924\n",
      "Real:283, Heu:53, Actual % Bugs,Clean: 0.774,0.822\n",
      "hive-0.9.0.csv 0.7735849056603774\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['size','IR','noise','#bug_n'],index=DATASETS,dtype='float')\n",
    "tmp = []\n",
    "for d in DATASETS:\n",
    "    X,y_noisy,y_real = read_data(d,stats=False)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_real,y_noisy).ravel()\n",
    "    print(f\"Real:{y_real.sum()}, Heu:{y_noisy.sum()}, Actual % Bugs,Clean: {tp/(tp+fp):.3f},{tn/(tn+fn):.3f}\")\n",
    "    if tp/(tp+fp) > .55:\n",
    "        print(d,tp/(tp+fp))\n",
    "        tmp.append(d)\n",
    "    imb = np.unique(y_noisy,return_counts=True)[1]\n",
    "    df.loc[d,'size'] = len(X)\n",
    "    df.loc[d,'IR'] = imb.max()/imb.min()\n",
    "    df.loc[d,'noise'] = (y_noisy!=y_real).sum()/len(X)\n",
    "    df.loc[d,'#bug_n'] = y_noisy.sum()\n",
    "df.to_csv(\"data_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['activemq-5.3.0.csv',\n",
       " 'lucene-2.3.0.csv',\n",
       " 'derby-10.2.1.6.csv',\n",
       " 'derby-10.3.1.4.csv',\n",
       " 'activemq-5.0.0.csv',\n",
       " 'derby-10.5.1.1.csv',\n",
       " 'hive-0.9.0.csv']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr(df['IR'],df['size']),spearmanr(df['IR'],df['size']),linregress(df['IR'],df['size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y_noisy,y_real = read_data(DATASETS[15],stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3).fit(X)\n",
    "Xp = pca.transform(X)\n",
    "pca.explained_variance_ratio_.sum(),pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(Xp[:,0],Xp[:,1],Xp[:,2],c=y_real);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = cross_val_predict(RandomForestClassifier(n_estimators=100),X,y_real,cv=10)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(Xp[:,0],Xp[:,1],Xp[:,2],c=yp);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = TSNE(n_components=3,perplexity=10).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(Xs[:,0],Xs[:,1],Xs[:,2],c=y_real);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"defect_pred'13/Original/AEEEM/PDE.arff\"\n",
    "df = pd.DataFrame(arff.loadarff(path)[0])\n",
    "label = 'class'\n",
    "enc = LabelEncoder().fit(df[label])\n",
    "df[label] = enc.transform(df[label])\n",
    "df.shape,np.unique(df.dtypes,return_counts=True),df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(df[label],return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = pd.DataFrame(StandardScaler().fit_transform(df.drop(columns=[label])))\n",
    "scaled[label] = df[label]\n",
    "scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.DataFrame(np.log1p(df.drop(columns=[label]).values))\n",
    "log[label] = df[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (18,20))\n",
    "ax = fig.gca()\n",
    "df.hist(ax = ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = log.drop(columns=[label]).values\n",
    "Y = df[label].values\n",
    "X,Y = shuffle(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = GridSearchCV(DecisionTreeClassifier(),{'max_leaf_nodes':[10,50,None]},cv=4,iid=False)\n",
    "rf = RandomForestClassifier(n_estimators=500)\n",
    "svm = GridSearchCV(SVC(gamma='scale'),{'C':[0.1, 1, 10]},cv=4,iid=False)\n",
    "knn = GridSearchCV(KNeighborsClassifier(),{'n_neighbors':[3,5,10,20]},cv=4,iid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_repeats=5,n_splits=10)\n",
    "res = cross_val_score(knn,X,Y,cv=cv,scoring='f1',n_jobs=-1)\n",
    "res.mean(),res.std(), res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(15).reshape(5,3)\n",
    "a[:,:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
