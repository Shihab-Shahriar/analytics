{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from time import perf_counter\n",
    "import numpy as np,os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, StratifiedKFold\n",
    "from imblearn.under_sampling import InstanceHardnessThreshold, RandomUnderSampler, EditedNearestNeighbours\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef, precision_recall_curve, auc, accuracy_score, precision_score, recall_score\n",
    "import seaborn as sns,matplotlib.pyplot as plt\n",
    "\n",
    "from library.configs import CLFS, CV, SCORERS\n",
    "from library.utils import evaluate, read_data\n",
    "from library.cleaners import kDN, ih_prob,FilteringEstimator\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASETS = ['groovy-1_5_7.csv','jruby-1.4.0.csv','lucene-2.9.0.csv','jruby-1.7.0.preview1.csv','groovy-1_6_BETA_1.csv',\n",
    "        'derby-10.2.1.6.csv','wicket-1.5.3.csv','camel-2.9.0.csv','camel-1.4.0.csv','activemq-5.8.0.csv']\n",
    "DATASETS = [f for f in os.listdir(\"JIRA/\") if 'csv' in f]\n",
    "len(DATASETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin, clone\n",
    "class Spyder(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self,estimator,K=5):\n",
    "        self.estimator = estimator\n",
    "        self.K = K\n",
    "        \n",
    "    def sample(self,X,Y,sample_weight):    # SPIDER2, relabel=False and ampl=weak by default\n",
    "        if sample_weight is None:\n",
    "            sample_weight = np.ones_like(Y)\n",
    "\n",
    "        # First step, Remove unsafe samples from majority, \n",
    "        enn = EditedNearestNeighbours(sampling_strategy='majority',n_neighbors=5,kind_sel='mode')\n",
    "        Xs,Ys = enn.fit_resample(X,Y)\n",
    "        sample_weight = sample_weight[enn.sample_indices_]\n",
    "            \n",
    "        #Second, upsample unsafe minority samples\n",
    "        disagreement = (kDN(Xs,Ys,K=5,weight='uniform') * 5).astype('int')\n",
    "        agreement = 5 - disagreement\n",
    "\n",
    "        n = disagreement - agreement  #Number of times to upsample\n",
    "        n[Ys==0] = 0  #Don't upsample majority-class samples\n",
    "        n[n<0] = 0\n",
    "\n",
    "        Xt,Yt,SWt = Xs.copy(),Ys.copy(),sample_weight.copy()\n",
    "        while n.sum()>0:\n",
    "            Xtmp, Ytmp, SWtmp = Xs[n>0].copy(),Ys[n>0].copy(),sample_weight[n>0].copy()\n",
    "            Xt,Yt,SWt = np.concatenate((Xt,Xtmp)),np.concatenate((Yt,Ytmp)),np.concatenate((SWt,SWtmp))\n",
    "            \n",
    "            n -= 1\n",
    "            n[n==-1] = 0\n",
    "            \n",
    "        return Xt,Yt,SWt\n",
    "    \n",
    "    def fit(self, X, Y,sample_weight=None):\n",
    "        Xf,Yf,sample_weight = self.sample(X, Y, sample_weight)\n",
    "#         a,b = np.unique(Y,return_counts=True)[1],np.unique(Yf,return_counts=True)[1]\n",
    "#         print(a.max()/a.min(),b.max()/b.min(),a,b,Xf.shape,len(Xf)/len(X))\n",
    "        assert len(np.unique(Yf))==2,\"Pos class completely filtered out\"\n",
    "        try:\n",
    "            self.estimator = self.estimator.fit(Xf, Yf,sample_weight=sample_weight)\n",
    "        except TypeError as e:\n",
    "            self.estimator = self.estimator.fit(Xf, Yf)\n",
    "        return self\n",
    "\n",
    "    @property\n",
    "    def classes_(self):\n",
    "        return self.estimator.classes_\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.estimator.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.estimator.predict_proba(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys([('Spyder', 'BagNB'), ('Spyder', 'BagDT')]), 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {}\n",
    "# for c,clf in CLFS.items():\n",
    "#     models[('Spyder',c)] = Spyder(clf)    \n",
    "    \n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "nb = GaussianNB()\n",
    "dt = DecisionTreeClassifier(max_depth=20,max_features='sqrt')\n",
    "models[('Spyder',\"BagNB\")] = BaggingClassifier(base_estimator=Spyder(nb),n_estimators=20)\n",
    "models[('Spyder',\"BagDT\")] = BaggingClassifier(base_estimator=Spyder(dt),n_estimators=20)\n",
    "    \n",
    "models.keys(),len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Spyder_Bag.csv\"\n",
    "cols = pd.MultiIndex.from_product([['Spyder'],[\"BagNB\",\"BagDT\"],[f.__name__ for f in SCORERS]],names=['imb','clf','metric'])\n",
    "df = pd.DataFrame(index=DATASETS,columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "activemq-5.8.0.csv noise:0.058, imb:15.847,203,3217, Shape:(3420, 65)\n",
      "('Spyder', 'BagNB')\n",
      "274.35 [0.284, 0.382]\n",
      "('Spyder', 'BagDT')\n",
      "275.95 [0.264, 0.322]\n",
      "\n",
      "1\n",
      "groovy-1_6_BETA_1.csv noise:0.128, imb:6.017,117,704, Shape:(821, 65)\n",
      "('Spyder', 'BagNB')\n",
      "203.73 [0.25, 0.369]\n",
      "('Spyder', 'BagDT')\n",
      "205.26 [0.451, 0.448]\n",
      "\n",
      "2\n",
      "activemq-5.3.0.csv noise:0.094, imb:15.669,142,2225, Shape:(2367, 65)\n",
      "('Spyder', 'BagNB')\n",
      "243.91 [0.332, 0.46]\n",
      "('Spyder', 'BagDT')\n",
      "241.42 [0.3, 0.468]\n",
      "\n",
      "3\n",
      "wicket-1.3.0-incubating-beta-1.csv noise:0.164, imb:4.806,288,1384, Shape:(1672, 65)\n",
      "('Spyder', 'BagNB')\n",
      "221.88 [0.313, 0.442]\n",
      "('Spyder', 'BagDT')\n",
      "222.74 [0.324, 0.328]\n",
      "\n",
      "4\n",
      "jruby-1.1.csv noise:0.175, imb:3.540,161,570, Shape:(731, 65)\n",
      "('Spyder', 'BagNB')\n",
      "201.83 [0.372, 0.616]\n",
      "('Spyder', 'BagDT')\n",
      "203.16 [0.478, 0.595]\n",
      "\n",
      "5\n",
      "jruby-1.4.0.csv noise:0.190, imb:3.890,200,778, Shape:(978, 65)\n",
      "('Spyder', 'BagNB')\n",
      "204.79 [0.429, 0.602]\n",
      "('Spyder', 'BagDT')\n",
      "206.92 [0.443, 0.581]\n",
      "\n",
      "6\n",
      "lucene-2.3.0.csv noise:0.204, imb:4.031,160,645, Shape:(805, 65)\n",
      "('Spyder', 'BagNB')\n",
      "205.18 [0.407, 0.596]\n",
      "('Spyder', 'BagDT')\n",
      "203.24 [0.532, 0.725]\n",
      "\n",
      "7\n",
      "hbase-0.95.2.csv noise:0.260, imb:15.088,114,1720, Shape:(1834, 65)\n",
      "('Spyder', 'BagNB')\n",
      "230.51 [0.312, 0.54]\n",
      "('Spyder', 'BagDT')\n",
      "230.31 [0.177, 0.429]\n",
      "\n",
      "8\n",
      "lucene-3.0.0.csv noise:0.185, imb:6.037,190,1147, Shape:(1337, 65)\n",
      "('Spyder', 'BagNB')\n",
      "220.87 [0.304, 0.308]\n",
      "('Spyder', 'BagDT')\n",
      "218.63 [0.176, 0.286]\n",
      "\n",
      "9\n",
      "camel-2.9.0.csv noise:0.044, imb:34.600,200,6920, Shape:(7120, 65)\n",
      "('Spyder', 'BagNB')\n",
      "549.64 [0.219, 0.344]\n",
      "('Spyder', 'BagDT')\n",
      "561.64 [0.212, 0.201]\n",
      "\n",
      "10\n",
      "wicket-1.5.3.csv noise:0.064, imb:26.720,93,2485, Shape:(2578, 65)\n",
      "('Spyder', 'BagNB')\n",
      "261.78 [0.201, 0.292]\n",
      "('Spyder', 'BagDT')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shihab/anaconda3/envs/ana/lib/python3.7/site-packages/sklearn/metrics/_classification.py:896: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/home/shihab/anaconda3/envs/ana/lib/python3.7/site-packages/sklearn/metrics/_classification.py:896: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264.93 [0.077, 0.166]\n",
      "\n",
      "11\n",
      "lucene-3.1.csv noise:0.120, imb:7.477,331,2475, Shape:(2806, 65)\n",
      "('Spyder', 'BagNB')\n",
      "271.36 [0.174, 0.21]\n",
      "('Spyder', 'BagDT')\n",
      "273.66 [0.174, 0.157]\n",
      "\n",
      "12\n",
      "groovy-1_6_BETA_2.csv noise:0.096, imb:7.583,103,781, Shape:(884, 65)\n",
      "('Spyder', 'BagNB')\n",
      "211.66 [0.232, 0.318]\n",
      "('Spyder', 'BagDT')\n",
      "211.23 [0.384, 0.463]\n",
      "\n",
      "13\n",
      "activemq-5.2.0.csv noise:0.113, imb:12.247,154,1886, Shape:(2040, 65)\n",
      "('Spyder', 'BagNB')\n",
      "237.22 [0.356, 0.544]\n",
      "('Spyder', 'BagDT')\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for it,d in enumerate(DATASETS):\n",
    "    print(it)\n",
    "    X,y_noisy,y_real = read_data(d,stats=True)\n",
    "    for k in models:\n",
    "        print(k)\n",
    "        sd = perf_counter()\n",
    "        r = evaluate(models[k],X,y_noisy,y_real,CV,SCORERS)\n",
    "        for f in r:\n",
    "            df.loc[d,(k[0],k[1],f)] = r[f].mean()\n",
    "        print(round(perf_counter()-sd,2),[round(r[f].mean(),3) for f in r])\n",
    "    print()\n",
    "    df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
