{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from time import perf_counter\n",
    "import numpy as np,os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, StratifiedKFold\n",
    "from imblearn.under_sampling import InstanceHardnessThreshold, RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef, precision_recall_curve, auc, accuracy_score, precision_score, recall_score\n",
    "import seaborn as sns,matplotlib.pyplot as plt\n",
    "\n",
    "from library.configs import IMBS, CLFS, ENSEMBLES, CV, SCORERS\n",
    "from library.utils import evaluate, read_data\n",
    "from library.cleaners import kDN, ih_prob,FilteringEstimator\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASETS = ['groovy-1_5_7.csv','jruby-1.4.0.csv','lucene-2.9.0.csv','jruby-1.7.0.preview1.csv','groovy-1_6_BETA_1.csv',\n",
    "        'derby-10.2.1.6.csv','wicket-1.5.3.csv','camel-2.9.0.csv','camel-1.4.0.csv','activemq-5.8.0.csv']\n",
    "DATASETS = [f for f in os.listdir(\"JIRA/\") if 'csv' in f]\n",
    "len(DATASETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin, clone\n",
    "class IHFilter(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self,estimator,threshold=.5):\n",
    "        self.estimator = estimator\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def clean(self,X,Y,sample_weight):\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "        rf = RandomForestClassifier(n_estimators=50,n_jobs=4)\n",
    "        \n",
    "        probabilities = np.zeros(Y.shape[0], dtype=float)\n",
    "        for train_index, test_index in skf.split(X,Y):\n",
    "            rf.fit(X[train_index], Y[train_index])\n",
    "            probs = rf.predict_proba(X[test_index])\n",
    "            probabilities[test_index] = probs[range(len(test_index)), Y[test_index]]\n",
    "            \n",
    "        hardness = 1 - probabilities\n",
    "        clean_idx = hardness <= self.threshold\n",
    "        \n",
    "        try:\n",
    "            sample_weight = sample_weight[clean_idx]\n",
    "        except:\n",
    "            pass\n",
    "        Xt,Yt = X[clean_idx],Y[clean_idx]\n",
    "        return Xt,Yt,sample_weight\n",
    "    \n",
    "    def fit(self, X, Y,sample_weight=None):\n",
    "        Xf,Yf,sample_weight = self.clean(X, Y, sample_weight)\n",
    "#         a,b = np.unique(Y,return_counts=True)[1],np.unique(Yf,return_counts=True)[1]\n",
    "#         print(a.max()/a.min(),b.max()/b.min(),a,b,Xf.shape,len(Xf)/len(X))\n",
    "        assert len(np.unique(Yf))==2,\"Pos class completely filtered out\"\n",
    "        try:\n",
    "            self.estimator = self.estimator.fit(Xf, Yf,sample_weight=sample_weight)\n",
    "        except TypeError as e:\n",
    "            self.estimator = self.estimator.fit(Xf, Yf)\n",
    "        return self\n",
    "\n",
    "    @property\n",
    "    def classes_(self):\n",
    "        return self.estimator.classes_\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.estimator.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.estimator.predict_proba(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys([('smote', 'dt'), ('smote', 'lr'), ('smote', 'nb'), ('smote', 'svm'), ('smote', 'knn'), ('smote', 'rf'), ('rus', 'dt'), ('rus', 'lr'), ('rus', 'nb'), ('rus', 'svm'), ('rus', 'knn'), ('rus', 'rf'), ('wilson', 'dt'), ('wilson', 'lr'), ('wilson', 'nb'), ('wilson', 'svm'), ('wilson', 'knn'), ('wilson', 'rf'), ('tomek', 'dt'), ('tomek', 'lr'), ('tomek', 'nb'), ('tomek', 'svm'), ('tomek', 'knn'), ('tomek', 'rf'), ('None', 'dt'), ('None', 'lr'), ('None', 'nb'), ('None', 'svm'), ('None', 'knn'), ('None', 'rf'), ('ens', 'rboost_DT'), ('ens', 'rboost_NB'), ('ens', 'bbag_DT'), ('ens', 'bbag_NB')]),\n",
       " 34)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {}\n",
    "for im,samp in IMBS.items():\n",
    "    for c,clf in CLFS.items():\n",
    "        models[(im,c)] = Pipeline([('samp',samp),('clf',IHFilter(clf))])\n",
    "\n",
    "for m,ens in ENSEMBLES.items():\n",
    "    ens = clone(ens)\n",
    "    ens.base_estimator = IHFilter(ens.base_estimator)\n",
    "    models[('ens',m)] = ens\n",
    "    \n",
    "models.keys(),len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = pd.MultiIndex.from_product([IMBS.keys(),CLFS.keys(),[f.__name__ for f in SCORERS]],names=['imb','clf','metric'])\n",
    "df = pd.DataFrame(index=DATASETS,columns=cols)\n",
    "#df = pd.read_csv(\"IHFilter.csv\",header=[0,1,2],index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activemq-5.8.0.csv noise:0.058, imb:15.847,203,3217, Shape:(3420, 65)\n",
      "('smote', 'dt')\n",
      "43.01 [0.202, 0.282]\n",
      "('smote', 'lr')\n",
      "50.67 [0.259, 0.305]\n",
      "('smote', 'nb')\n",
      "40.56 [0.29, 0.402]\n",
      "('smote', 'svm')\n",
      "198.38 [0.251, 0.201]\n",
      "('smote', 'knn')\n",
      "42.85 [0.215, 0.29]\n",
      "('smote', 'rf')\n",
      "52.37 [0.266, 0.289]\n",
      "('rus', 'dt')\n",
      "27.45 [0.229, 0.466]\n",
      "('rus', 'lr')\n",
      "27.98 [0.247, 0.311]\n",
      "('rus', 'nb')\n",
      "27.25 [0.273, 0.451]\n",
      "('rus', 'svm')\n",
      "27.69 [0.243, 0.243]\n",
      "('rus', 'knn')\n",
      "27.62 [0.241, 0.407]\n",
      "('rus', 'rf')\n",
      "28.88 [0.253, 0.314]\n",
      "('wilson', 'dt')\n",
      "33.73 [0.263, 0.328]\n",
      "('wilson', 'lr')\n",
      "36.19 [0.282, 0.322]\n",
      "('wilson', 'nb')\n",
      "33.06 [0.293, 0.399]\n",
      "('wilson', 'svm')\n",
      "37.72 [0.299, 0.294]\n",
      "('wilson', 'knn')\n",
      "36.85 [0.251, 0.304]\n",
      "('wilson', 'rf')\n",
      "39.35 [0.299, 0.338]\n",
      "('tomek', 'dt')\n",
      "34.18 [0.246, 0.372]\n",
      "('tomek', 'lr')\n",
      "35.08 [0.266, 0.34]\n",
      "('tomek', 'nb')\n",
      "33.48 [0.303, 0.346]\n",
      "('tomek', 'svm')\n",
      "35.73 [0.273, 0.207]\n",
      "('tomek', 'knn')\n",
      "34.22 [0.25, 0.392]\n",
      "('tomek', 'rf')\n",
      "34.68 [0.28, 0.341]\n",
      "('None', 'dt')\n",
      "28.84 [0.25, 0.391]\n",
      "('None', 'lr')\n",
      "29.92 [0.256, 0.342]\n",
      "('None', 'nb')\n",
      "27.48 [0.3, 0.339]\n",
      "('None', 'svm')\n",
      "30.21 [0.247, 0.196]\n",
      "('None', 'knn')\n",
      "29.07 [0.235, 0.385]\n",
      "('None', 'rf')\n",
      "30.1 [0.279, 0.336]\n",
      "('ens', 'rboost_DT')\n",
      "114.06 [0.24, 0.413]\n",
      "('ens', 'rboost_NB')\n",
      "116.49 [0.273, 0.44]\n",
      "('ens', 'bbag_DT')\n"
     ]
    }
   ],
   "source": [
    "for d in DATASETS:\n",
    "    X,y_noisy,y_real = read_data(d,stats=True)\n",
    "    if df.loc[d,:].isna().sum()==0:\n",
    "        print(f\"SKIPPING {d}\\n\")\n",
    "        continue\n",
    "    for k in models:\n",
    "        print(k)\n",
    "        sd = perf_counter()\n",
    "        r = evaluate(models[k],X,y_noisy,y_real,CV,SCORERS)\n",
    "        for f in r:\n",
    "            df.loc[d,(k[0],k[1],f)] = r[f].mean()\n",
    "        print(round(perf_counter()-sd,2),[round(r[f].mean(),3) for f in r])\n",
    "    print()\n",
    "    df.to_csv(\"IHFilter.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
