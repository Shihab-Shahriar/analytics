{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "import numpy as np,os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors.base import _get_weights\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from imblearn.ensemble import BalancedBaggingClassifier, RUSBoostClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, EditedNearestNeighbours, TomekLinks\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef, precision_recall_curve, auc, accuracy_score, precision_score, recall_score\n",
    "import seaborn as sns,matplotlib.pyplot as plt\n",
    "\n",
    "from library.configs import IMBS, CLFS, CV, SCORERS\n",
    "from library.utils import evaluate, read_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASETS = ['groovy-1_5_7.csv','jruby-1.4.0.csv','lucene-2.9.0.csv','jruby-1.7.0.preview1.csv','groovy-1_6_BETA_1.csv',\n",
    "        'derby-10.2.1.6.csv','wicket-1.5.3.csv','camel-2.9.0.csv','camel-1.4.0.csv','activemq-5.8.0.csv']\n",
    "DATASETS = [f for f in os.listdir(\"JIRA/\") if 'csv' in f]\n",
    "len(DATASETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin, clone\n",
    "\n",
    "def kDN(X, Y, K=5, n_jobs=-1,weight='uniform', **kwargs):\n",
    "    knn = KNeighborsClassifier(n_neighbors=K, n_jobs=n_jobs, weights=weight).fit(X, Y)\n",
    "    dist, kid = knn.kneighbors()  # (N,K) : ids & dist of nn's for every sample in X\n",
    "    weights = _get_weights(dist, weight)\n",
    "    if weights is None:\n",
    "        weights = np.ones_like(kid)\n",
    "    disagreement = Y[kid] != Y.reshape(-1, 1)\n",
    "    return np.average(disagreement, axis=1, weights=weights)\n",
    "\n",
    "class CLNI(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, estimator, detector, K=5, threshold=.999, random_state=None):\n",
    "        self.estimator = estimator\n",
    "        self.detector = detector\n",
    "        self.threshold = threshold\n",
    "        self.K = K\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def clean(self,X,Y, sample_weight):\n",
    "        N,alpha = 5,.60\n",
    "        Xt,Yt = X.copy(),Y.copy()\n",
    "        while True:\n",
    "            ne = self.detector(Xt,Yt,K=self.K)\n",
    "            cidx = ne<=alpha\n",
    "            #print(cidx.sum(),len(Xt),cidx.sum()/len(Xt))\n",
    "            N = len(Xt)\n",
    "            Xt,Yt = Xt[cidx],Yt[cidx]\n",
    "            try:\n",
    "                sample_weight = sample_weight[cidx]\n",
    "            except:\n",
    "                pass\n",
    "            if cidx.sum()/N>=.99:\n",
    "                break\n",
    "        return Xt,Yt,sample_weight\n",
    "\n",
    "    def fit(self, X, Y,sample_weight=None):\n",
    "        Xf,Yf,sample_weight = self.clean(X, Y, sample_weight)\n",
    "#         a,b = np.unique(Y,return_counts=True)[1],np.unique(Yf,return_counts=True)[1]\n",
    "#         print(a.max()/a.min(),b.max()/b.min())\n",
    "        assert len(np.unique(Yf))==2,\"Pos class completely filtered out\"\n",
    "        try:\n",
    "            self.estimator = self.estimator.fit(Xf, Yf,sample_weight=sample_weight)\n",
    "        except TypeError as e:\n",
    "            self.estimator = self.estimator.fit(Xf, Yf)\n",
    "        return self\n",
    "\n",
    "    @property\n",
    "    def classes_(self):\n",
    "        return self.estimator.classes_\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.estimator.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.estimator.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "models = {}\n",
    "for im,samp in IMBS.items():\n",
    "    for c,clf in CLFS.items():\n",
    "        models[(im,c)] = Pipeline([('samp',samp),('clf',CLNI(clf,kDN))])\n",
    "    \n",
    "models.keys(),len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"CLNI_consensus.csv\"\n",
    "cols = pd.MultiIndex.from_product([IMBS.keys(),CLFS.keys(),[f.__name__ for f in SCORERS]],names=['imb','clf','metric'])\n",
    "df = pd.DataFrame(index=DATASETS,columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for it,d in enumerate(DATASETS):\n",
    "    print(it)\n",
    "    X,y_noisy,y_real = read_data(d,stats=True)\n",
    "    if df.loc[d,:].isna().sum()==0:\n",
    "        print(f\"Skipping {d}\")\n",
    "        #continue\n",
    "    for k in models:\n",
    "        print(k)\n",
    "        sd = perf_counter()\n",
    "        r = evaluate(models[k],X,y_noisy,y_real,CV,SCORERS)\n",
    "        for f in r:\n",
    "            df.loc[d,(k[0],k[1],f)] = np.nanmean(r[f])\n",
    "        print(round(perf_counter()-sd,2),[round(r[f].mean(),3) for f in r])\n",
    "    print()\n",
    "    df.to_csv(\"CLNI_consensus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camel-2.9.0.csv noise:0.044, imb:34.600,200,6920, Shape:(7120, 65)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "X,yn,yr = read_data(DATASETS[8],True)\n",
    "xf,yf,yfr = CLNI(DummyClassifier(),kDN).clean(X,yn,yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004113412663434679"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "er1 = 1 - ((yf==yfr).sum()/(yn==yr).sum())\n",
    "er1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5239616613418531"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "er2 = (yf!=yfr).sum()/(yn!=yr).sum()\n",
    "er2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
